{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5cfa97-ff38-48d8-b00e-c1f03b555974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Cleaning - Fixing the ARFF File\n",
    "\n",
    "def fix_arff_file(filepath, output_filepath):\n",
    "    # Read the ARFF file as text\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Process lines to find and rename duplicate columns\n",
    "    columns_seen = set()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.lower().startswith('@attribute'):\n",
    "            # Extract the column name\n",
    "            parts = line.split()\n",
    "            col_name = parts[1].strip(\"'\")\n",
    "            \n",
    "            # Check for duplicates\n",
    "            if col_name in columns_seen:\n",
    "                # Append a suffix to make it unique\n",
    "                new_col_name = f\"{col_name}_{len(columns_seen)}\"\n",
    "                lines[i] = line.replace(col_name, new_col_name)\n",
    "            else:\n",
    "                columns_seen.add(col_name)\n",
    "    \n",
    "    # Write the fixed lines to a new ARFF file\n",
    "    with open(output_filepath, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# Apply this function to your lung dataset\n",
    "fix_arff_file('Lung.arff', 'Lung_fixed.arff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ebdcd1-3242-42df-bedd-dc3415ae9f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AFFX-MurIL2_at  AFFX-MurIL10_at  AFFX-MurIL4_at  AFFX-MurFAS_at  \\\n",
      "0         -18.600            10.54           0.010          19.440   \n",
      "1           9.120             9.12          10.180          29.290   \n",
      "2          -2.175            -2.21          -0.060           6.320   \n",
      "3          -1.540            21.75           5.835          23.815   \n",
      "4          -9.070             3.08          -1.980          17.260   \n",
      "\n",
      "   AFFX-BioB-5_at  AFFX-BioB-M_at  AFFX-BioB-3_at  AFFX-BioC-5_at  \\\n",
      "0         -16.980          -27.50          -1.600           38.88   \n",
      "1          -4.680           -1.50          -3.620           20.80   \n",
      "2          -1.775          -16.53          -3.610           16.41   \n",
      "3         -24.785          -12.89          -4.485           19.50   \n",
      "4         -10.090          -15.15         -18.190           13.21   \n",
      "\n",
      "   AFFX-BioC-3_at  AFFX-BioDn-5_at  ...  101_at  102_at  103_at  104_at  \\\n",
      "0         -29.120          -42.870  ...   8.110  33.210  30.780   47.80   \n",
      "1         -13.180          -35.470  ...  15.490  27.170  26.110   45.22   \n",
      "2         -17.970          -57.020  ...  14.610  10.875  10.615   35.14   \n",
      "3         -21.445          -47.205  ...   9.615  27.355  30.860   48.71   \n",
      "4         -13.130          -39.470  ... -14.140  23.340   6.120   33.46   \n",
      "\n",
      "   105_at  106_at  107_at  108_g_at   109_at  type  \n",
      "0   1.630  17.020  13.780   -103.49   76.980     1  \n",
      "1  10.180  69.640 -24.850    -34.41  105.730     1  \n",
      "2   1.745  29.710  10.465    -42.63   73.735     1  \n",
      "3  10.355  40.845  54.615    -71.38   65.435     1  \n",
      "4 -10.090  40.550  16.250    -48.59   39.540     1  \n",
      "\n",
      "[5 rows x 12601 columns]\n",
      "AFFX-MurIL2_at     float64\n",
      "AFFX-MurIL10_at    float64\n",
      "AFFX-MurIL4_at     float64\n",
      "AFFX-MurFAS_at     float64\n",
      "AFFX-BioB-5_at     float64\n",
      "                    ...   \n",
      "106_at             float64\n",
      "107_at             float64\n",
      "108_g_at           float64\n",
      "109_at             float64\n",
      "type                object\n",
      "Length: 12601, dtype: object\n",
      "       AFFX-MurIL2_at  AFFX-MurIL10_at  AFFX-MurIL4_at  AFFX-MurFAS_at  \\\n",
      "count      203.000000       203.000000      203.000000      203.000000   \n",
      "mean        -7.878892         5.005411        0.517397       19.886711   \n",
      "std         20.561466        22.442965       19.207866       20.539096   \n",
      "min        -59.530000       -33.200000      -31.180000      -18.630000   \n",
      "25%        -21.172500       -10.007500      -12.720000        4.835000   \n",
      "50%        -10.290000         1.580000       -1.025000       16.880000   \n",
      "75%          5.215000        16.320000       10.252500       31.415000   \n",
      "max         92.680000       106.160000       70.500000       91.790000   \n",
      "\n",
      "       AFFX-BioB-5_at  AFFX-BioB-M_at  AFFX-BioB-3_at  AFFX-BioC-5_at  \\\n",
      "count      203.000000      203.000000      203.000000      203.000000   \n",
      "mean       -15.501396      -21.921300       -4.494465       22.679596   \n",
      "std         19.429433       26.057907       25.477561       26.182165   \n",
      "min        -67.000000     -263.470000      -44.000000      -34.810000   \n",
      "25%        -27.441500      -33.592500      -18.542500        3.725000   \n",
      "50%        -18.450000      -22.480000       -8.240000       19.890000   \n",
      "75%         -4.290000      -10.862500        3.697500       39.870000   \n",
      "max         47.860000       53.660000      210.100000      114.500000   \n",
      "\n",
      "       AFFX-BioC-3_at  AFFX-BioDn-5_at  ...    100_g_at      101_at  \\\n",
      "count      203.000000       203.000000  ...  203.000000  203.000000   \n",
      "mean       -23.922005       -53.161064  ...  138.986207    5.784229   \n",
      "std         16.143768        17.558313  ...   46.487026   20.743648   \n",
      "min        -57.040000       -99.730000  ...   42.050000  -48.980000   \n",
      "25%        -35.080000       -64.685000  ...  105.060000   -7.932500   \n",
      "50%        -25.615000       -56.090000  ...  132.290000    5.470000   \n",
      "75%        -14.355000       -43.895000  ...  165.625000   18.745000   \n",
      "max         22.295000        16.420000  ...  289.930000   74.320000   \n",
      "\n",
      "           102_at      103_at      104_at      105_at      106_at      107_at  \\\n",
      "count  203.000000  203.000000  203.000000  203.000000  203.000000  203.000000   \n",
      "mean    18.357938   15.485242   44.789512    2.246124   36.781918   32.090163   \n",
      "std     21.248038   35.389611   24.657876   19.098935   23.458006   44.926864   \n",
      "min    -34.440000  -29.750000  -10.440000  -32.620000  -15.020000  -57.880000   \n",
      "25%      4.670000   -4.046650   26.755000  -11.170000   20.255000   -1.465000   \n",
      "50%     17.240000    9.310000   43.170000    0.745000   33.840000   27.350000   \n",
      "75%     30.320000   26.045000   58.127500   11.507500   51.785000   58.170000   \n",
      "max     86.820000  303.850000  142.390000   82.030000  115.840000  168.670000   \n",
      "\n",
      "         108_g_at      109_at  \n",
      "count  203.000000  203.000000  \n",
      "mean   -60.739424   71.572882  \n",
      "std     43.337251   28.929706  \n",
      "min   -188.470000    2.370000  \n",
      "25%    -87.765000   51.540000  \n",
      "50%    -60.080000   70.880000  \n",
      "75%    -35.925000   90.570000  \n",
      "max     45.720000  173.060000  \n",
      "\n",
      "[8 rows x 12600 columns]\n",
      "AFFX-MurIL2_at     0\n",
      "AFFX-MurIL10_at    0\n",
      "AFFX-MurIL4_at     0\n",
      "AFFX-MurFAS_at     0\n",
      "AFFX-BioB-5_at     0\n",
      "                  ..\n",
      "106_at             0\n",
      "107_at             0\n",
      "108_g_at           0\n",
      "109_at             0\n",
      "type               0\n",
      "Length: 12601, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "# Step 2.1: Load the Fixed ARFF File\n",
    "def load_arff_data(filepath):\n",
    "    # Load the ARFF file\n",
    "    data, meta = arff.loadarff(filepath)\n",
    "    \n",
    "    # Convert the data into a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Decode byte strings (if any) to standard strings\n",
    "    for column in df.select_dtypes([object]).columns:\n",
    "        df[column] = df[column].str.decode('utf-8')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the fixed lung dataset\n",
    "lung_df = load_arff_data('Lung_fixed.arff')\n",
    "\n",
    "# Step 2.2: Explore the Data\n",
    "# Display the first few rows of the dataset\n",
    "print(lung_df.head())\n",
    "\n",
    "# Check the data types of the columns\n",
    "print(lung_df.dtypes)\n",
    "\n",
    "# Get a summary of the data (e.g., number of missing values, basic stats)\n",
    "print(lung_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(lung_df.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(lung_df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276f986e-c32c-42ea-a1ba-cff603484553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 162\n",
      "Test set size: 41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "\n",
    "# Step 3.1: Handle the Target Variable\n",
    "def preprocess_target(df, target_col='type'):\n",
    "    le = LabelEncoder()\n",
    "    df[target_col] = le.fit_transform(df[target_col])\n",
    "    return df\n",
    "\n",
    "lung_df = preprocess_target(lung_df)\n",
    "\n",
    "# Step 3.2: Feature Selection\n",
    "def select_features(df, target_col='type', top_k=100):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # SelectKBest with ANOVA F-value\n",
    "    selector = SelectKBest(score_func=f_classif, k=top_k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    \n",
    "    # Get the indices of selected features\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_features = X.columns[selected_indices]\n",
    "    \n",
    "    return df[selected_features.tolist() + [target_col]]\n",
    "\n",
    "# Select top 100 features\n",
    "lung_df_selected = select_features(lung_df, top_k=100)\n",
    "\n",
    "# Step 3.3: Data Normalization/Standardization\n",
    "def normalize_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    X = df.drop(columns=['type'])\n",
    "    y = df['type']\n",
    "    \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return pd.DataFrame(X_scaled, columns=X.columns), y\n",
    "\n",
    "X_scaled, y = normalize_data(lung_df_selected)\n",
    "\n",
    "# Step 3.4: Split the Dataset\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "\n",
    "# Output some basic information about the splits\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8512fc71-e921-4e56-aa5d-33c6a03318cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2, f_classif, RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load ARFF data into DataFrame\n",
    "def load_arff_to_df(filepath):\n",
    "    data, meta = arff.loadarff(filepath)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "df = load_arff_to_df('Lung_fixed.arff')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['type'])\n",
    "y = df['type'].astype('str')  # Convert target to string if it's categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719aa2ad-9ecf-45a4-8807-fa03c27381e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "41325_at      0.522847\n",
      "38138_at      0.501622\n",
      "33322_i_at    0.487682\n",
      "36924_r_at    0.476928\n",
      "32254_at      0.472818\n",
      "                ...   \n",
      "33710_at      0.000000\n",
      "33698_at      0.000000\n",
      "1601_s_at     0.000000\n",
      "33253_at      0.000000\n",
      "36465_at      0.000000\n",
      "Length: 12600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# 1. Mutual Information\n",
    "mi = mutual_info_classif(X, y)\n",
    "mi_scores = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Mutual Information Scores:\")\n",
    "print(mi_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91487f7-5f04-4db4-8d2e-38d0d7a7b191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Scores:\n",
      "40808_at      792239.030250\n",
      "33377_at      420249.997973\n",
      "32252_at      419108.344009\n",
      "613_at        323155.060274\n",
      "39026_r_at    320199.463616\n",
      "                  ...      \n",
      "1821_at                 NaN\n",
      "1777_at                 NaN\n",
      "1374_g_at               NaN\n",
      "499_at                  NaN\n",
      "345_at                  NaN\n",
      "Length: 12600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Ensure data is non-negative\n",
    "X_non_negative = X.clip(lower=0)\n",
    "\n",
    "# 2. Chi-Square\n",
    "chi2_selector = SelectKBest(chi2, k='all')\n",
    "X_chi2 = chi2_selector.fit_transform(X_non_negative, y)\n",
    "chi2_scores = pd.Series(chi2_selector.scores_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Chi-Square Scores:\")\n",
    "print(chi2_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3f7f1d-54ae-451b-9a15-27c0c26e77aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA F-Value Scores:\n",
      "36160_s_at    368.030678\n",
      "32254_at      342.758796\n",
      "36148_at      321.307693\n",
      "40825_at      298.749976\n",
      "40165_at      268.788325\n",
      "                 ...    \n",
      "36600_at        0.107660\n",
      "33659_at        0.102819\n",
      "1818_at         0.081640\n",
      "38189_s_at      0.068180\n",
      "847_at          0.036264\n",
      "Length: 12600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# 3. ANOVA F-Value\n",
    "f_values, _ = f_classif(X, y)\n",
    "anova_scores = pd.Series(f_values, index=X.columns).sort_values(ascending=False)\n",
    "print(\"ANOVA F-Value Scores:\")\n",
    "print(anova_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddfd9c7-5086-4014-91fb-fc021d60e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Selected Features with Scaling:\n",
      "Index(['31638_at', '33693_at', '33529_at', '35414_s_at', '37422_at',\n",
      "       '37826_at', '38202_at', '38918_at', '39581_at', '39625_at', '39670_at',\n",
      "       '40304_at', '41385_at', '31791_at', '32025_at', '32028_at', '32034_at',\n",
      "       '32626_at', '33230_at', '33808_at', '35177_at', '37603_at', '38643_at',\n",
      "       '39685_at', '39795_at', '39799_at', '40128_at', '40410_at', '40766_at',\n",
      "       '40808_at', '41156_g_at', '41197_at', '33375_at', '33423_g_at',\n",
      "       '35840_at', '36105_at', '36139_at', '36209_at', '37044_at', '37363_at',\n",
      "       '38368_at', '38814_at', '39561_at', '40581_at', '40961_at', '41337_at',\n",
      "       '41338_at', '41498_at', '41809_at', '1420_s_at', '1317_at', '897_at',\n",
      "       '613_at', '402_s_at', '376_at', '319_g_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply Lasso with standardized features\n",
    "lasso = Lasso(alpha=0.1)  # Adjust alpha as needed\n",
    "lasso.fit(X_scaled, y)\n",
    "model = SelectFromModel(lasso, prefit=True)\n",
    "X_lasso = model.transform(X_scaled)\n",
    "lasso_support = model.get_support()\n",
    "lasso_features = X.columns[lasso_support]\n",
    "print(\"Lasso Selected Features with Scaling:\")\n",
    "print(lasso_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d1e37ca-1586-47eb-ba64-29b935fe4633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Threshold Scores:\n",
      "35553_at      1.0\n",
      "39768_at      1.0\n",
      "39872_at      1.0\n",
      "1592_at       1.0\n",
      "32255_i_at    1.0\n",
      "             ... \n",
      "33331_at      1.0\n",
      "35739_at      1.0\n",
      "40908_r_at    1.0\n",
      "34623_at      1.0\n",
      "32957_g_at    1.0\n",
      "Length: 12600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 5. Variance Threshold\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "variance_threshold = VarianceThreshold(threshold=0.01)  # Adjust the threshold as needed\n",
    "X_var = variance_threshold.fit_transform(X_scaled)\n",
    "var_scores = pd.Series(variance_threshold.variances_, index=X.columns[variance_threshold.get_support()]).sort_values(ascending=False)\n",
    "print(\"Variance Threshold Scores:\")\n",
    "print(var_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fc2ef-4ea9-477c-a753-0c1b14b6b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 6. Recursive Feature Elimination (RFE)\n",
    "rfe_model = RandomForestClassifier()\n",
    "rfe = RFE(estimator=rfe_model, n_features_to_select=10)  # Select the top 10 features\n",
    "rfe.fit(X, y)\n",
    "rfe_support = pd.Series(rfe.support_, index=X.columns)\n",
    "rfe_ranking = pd.Series(rfe.ranking_, index=X.columns).sort_values(ascending=True)\n",
    "print(\"RFE Feature Rankings (1 is best):\")\n",
    "print(rfe_ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fba7a-49a2-4946-a843-3ce7c8f73fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 7. Tree-based Feature Selection\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest.fit(X, y)\n",
    "forest_importances = pd.Series(forest.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(forest_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c24492a-15c7-46ec-a1f9-465719dc50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Feature Scores:\n",
      "40808_at      264162.129960\n",
      "33377_at      140102.462342\n",
      "32252_at      139720.702199\n",
      "613_at        107748.424703\n",
      "39026_r_at    106783.115692\n",
      "                  ...      \n",
      "1869_at            0.185449\n",
      "37113_at           0.183769\n",
      "40531_at           0.178674\n",
      "34627_at           0.174206\n",
      "38189_s_at         0.022727\n",
      "Name: Average, Length: 12600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Combine scores from different methods\n",
    "combined_scores = pd.DataFrame({\n",
    "    'Mutual Information': mi_scores,\n",
    "    'Chi-Square': chi2_scores,\n",
    "    'ANOVA F-Value': anova_scores\n",
    "}).fillna(0)\n",
    "\n",
    "# Compute average score for each feature\n",
    "combined_scores['Average'] = combined_scores.mean(axis=1)\n",
    "\n",
    "# Sort by average score\n",
    "combined_scores_sorted = combined_scores['Average'].sort_values(ascending=False)\n",
    "print(\"Combined Feature Scores:\")\n",
    "print(combined_scores_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e548940-cd31-4c23-bc47-2c66450bcd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPSIS Scores:\n",
      "40808_at      1.000000e+00\n",
      "33377_at      5.303654e-01\n",
      "32252_at      5.289202e-01\n",
      "613_at        4.078874e-01\n",
      "39026_r_at    4.042332e-01\n",
      "                  ...     \n",
      "1869_at       6.159950e-07\n",
      "37113_at      6.096356e-07\n",
      "40531_at      5.903472e-07\n",
      "34627_at      5.734324e-07\n",
      "38189_s_at    0.000000e+00\n",
      "Length: 12600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize scores\n",
    "scaler = MinMaxScaler()\n",
    "normalized_scores = scaler.fit_transform(combined_scores_sorted.values.reshape(-1, 1))\n",
    "\n",
    "# Construct decision matrix\n",
    "decision_matrix = pd.DataFrame(normalized_scores, index=combined_scores_sorted.index, columns=['Score'])\n",
    "\n",
    "# Determine ideal and negative-ideal solutions\n",
    "ideal_solution = decision_matrix.max()\n",
    "negative_ideal_solution = decision_matrix.min()\n",
    "\n",
    "# Calculate distances\n",
    "distance_to_ideal = np.sqrt(((decision_matrix - ideal_solution) ** 2).sum(axis=1))\n",
    "distance_to_negative_ideal = np.sqrt(((decision_matrix - negative_ideal_solution) ** 2).sum(axis=1))\n",
    "\n",
    "# Calculate TOPSIS scores\n",
    "topsis_scores = distance_to_negative_ideal / (distance_to_negative_ideal + distance_to_ideal)\n",
    "\n",
    "# Rank features\n",
    "ranked_features = pd.Series(topsis_scores, index=combined_scores_sorted.index).sort_values(ascending=False)\n",
    "print(\"TOPSIS Scores:\")\n",
    "print(ranked_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7eb14a-0d60-404a-b580-5e349caf0452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features Based on TOPSIS Scores:\n",
      "40808_at      1.000000\n",
      "33377_at      0.530365\n",
      "32252_at      0.528920\n",
      "613_at        0.407887\n",
      "39026_r_at    0.404233\n",
      "                ...   \n",
      "40423_at      0.005130\n",
      "37360_at      0.005120\n",
      "36945_at      0.005119\n",
      "34592_at      0.005114\n",
      "39294_at      0.005114\n",
      "Length: 1260, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_features = ranked_features.head(int(0.1 * len(ranked_features)))  # Select top 10%\n",
    "print(\"Top Features Based on TOPSIS Scores:\")\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259f50bb-1943-4887-94e0-d7783c3231bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of extracting top features from the original dataset\n",
    "top_features_names = top_features.index\n",
    "X_top_features = X[top_features_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdac0f69-3078-42dd-8a46-f238d751134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with Top Features: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy with Top Features: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ee1e2a-dcda-44fa-8a2e-5fba008dbb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "         Feature  Importance\n",
      "899     38368_at    0.015887\n",
      "96      41338_at    0.012780\n",
      "819     32591_at    0.012300\n",
      "101     39266_at    0.012051\n",
      "919     41418_at    0.011675\n",
      "...          ...         ...\n",
      "563   31951_s_at    0.000000\n",
      "564     31722_at    0.000000\n",
      "565     38261_at    0.000000\n",
      "566     38604_at    0.000000\n",
      "1259    39294_at    0.000000\n",
      "\n",
      "[1260 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': top_features_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f205000d-c6b1-4775-bfe2-e99c1cc85a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Accuracy: 0.9293103448275863\n",
      "Optimized Model Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Optimized Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81674f9c-ae05-49b7-aaf0-70ea14bf7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\miniconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert string labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_numeric = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data with numeric labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_numeric, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c27eafa-f415-4a58-b73a-23bf3e692d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\miniconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:15:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize models\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Create Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb_model)], voting='soft')\n",
    "\n",
    "# Train Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "638ffe0c-99d3-43dc-868a-417c5113659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Initialize PolynomialFeatures with a lower degree\n",
    "poly = PolynomialFeatures(degree=1)  # Degree 1 is equivalent to original features\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Proceed with splitting and training\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(X_poly, y_numeric, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c10f64b-591d-4739-8ffc-4896f002a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with Feature Selection and PCA: 0.74\n",
      "Feature Importances:\n",
      "     Feature  Importance\n",
      "2          2    0.101832\n",
      "3          3    0.087548\n",
      "1          1    0.084369\n",
      "0          0    0.043300\n",
      "13        13    0.040454\n",
      "..       ...         ...\n",
      "26        26    0.001433\n",
      "123      123    0.001296\n",
      "122      122    0.001117\n",
      "125      125    0.001089\n",
      "31        31    0.001036\n",
      "\n",
      "[128 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature Selection using RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_scaled, y)\n",
    "feature_importances = rf_model.feature_importances_\n",
    "important_features = SelectFromModel(rf_model, threshold='mean', prefit=True)\n",
    "X_important = important_features.transform(X_scaled)\n",
    "\n",
    "# Dimensionality Reduction using PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_important)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy with Feature Selection and PCA: {accuracy:.2f}\")\n",
    "\n",
    "# Feature Importances\n",
    "importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': np.arange(len(importances)), 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef2ed5a2-c6d7-4004-a58a-8b6533bd89ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\miniconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:16:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Train model\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_encoded = xgb_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d6d27-f004-4ccd-b590-64b3b147c80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
